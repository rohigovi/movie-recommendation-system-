# -*- coding: utf-8 -*-
"""Modelling_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lzexgg9308i9IaW7KZCdBoxbpZVEqJJB
"""



#importing the necessary packages
import numpy as np
import pandas as pd
from surprise import Reader
from surprise import KNNWithMeans
from surprise import Dataset
import pickle

pip install surprise

#movie_df_csv = pd.read_csv('sample-user-movie-df.csv')
movie_df_csv = pd.read_csv('watched_rated_df.csv')

len(movie_df_csv)

movie_df_csv.head()

df_sub = movie_df_csv[['userid','movieid','rating']]

reader = Reader(rating_scale=(1, 5))

# df_sub = Dataset.load_from_df(df_sub[['userid','movieid','rating']], reader)

type(df_sub)

from surprise.model_selection import cross_validate

# trainSet = data.build_full_trainset()
algo = KNNWithMeans()
# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)

from surprise import accuracy, Dataset, SVD
# from surprise.model_selection import train_test_split

from sklearn.model_selection import train_test_split
train, test = train_test_split(df_sub, test_size=0.2)

# trainset = train_test_split()

# algo.fit(trainset)
# predictions = algo.test(testset)

# # Then compute RMSE
# accuracy.rmse(predictions)

type(train)

from surprise.model_selection import GridSearchCV

data_train = Dataset.load_from_df(train[['userid','movieid','rating']], reader)

sim_options = {
    "name": ["cosine"],
    "min_support": [3, 4, 5],
    "user_based": [False, True],
}
param_grid = {"sim_options": sim_options}
gs = GridSearchCV(KNNWithMeans, param_grid, measures=["rmse", "mae"], cv=4)
gs.fit(data_train)

# from surprise import accuracy, Dataset, SVD
# from surprise.model_selection import train_test_split

# trainset, testset = train_test_split(data, test_size=0.2)

trainingSet = data_train.build_full_trainset()

knn_algo = KNNWithMeans(sim_options=gs.best_params)
knn_algo.fit(trainingSet)

def rmse(predictions, targets):
    return np.sqrt(((predictions - targets) ** 2).mean())

from tqdm import tqdm
predictions = []
actuals = []
rmse_val = []
for col, row in tqdm(test.iterrows()):
    predictions.append(knn_algo.predict(row.userid, row.movieid).est)
    actuals.append(row.rating)

rmse_val = rmse(np.array(predictions), np.array(actuals))

print("Test Accuracy KNN = " + str(rmse_val))

import random
master_movie_list = movie_df_csv['movieid'].unique().tolist()
top_20 = movie_df_csv.groupby(['movieid']).mean().rating.sort_values(0, ascending = False)[0:20]
top_20_tup = [(top_20.index[i], top_20.values[i]) for i in range(len(top_20.values))]
def get_recommendations(userId,model):
    if(userId not in movie_df_csv['userid'].values.tolist()):
        return random.sample(top_20_tup, len(top_20_tup))
    watched_list = movie_df_csv[movie_df_csv['userid'] == userId]['movieid'].unique().tolist()
    pred_movies = [i for i in master_movie_list if i not in watched_list]
    pred_dict = dict()
    for i in pred_movies:
        pred_dict[i] = model.predict(userId, i).est
    pred_dict = sorted(pred_dict.items(), key=lambda x: -x[1])
    if(len(pred_dict) < 20):
        return pred_dict
    else:
        return pred_dict[:20]
    return pred_dict

filename = 'KNN_14k'
outfile = open(filename,'wb')
pickle.dump(knn_algo,outfile)
outfile.close()

#Sample inference
preds = get_recommendations(23422222222222222222222222222222222222,knn_algo)

preds

#adding Model based CF

from surprise import SVD
from surprise.model_selection import GridSearchCV

"""
lr_all is the learning rate for all parameters (how much the parameters are adjusted in each iteration)
reg_all is the regularization term for all parameters, which is a penalty term added to prevent overfitting.
This creates a model object called svd_algo
"""
param_grid = {
    "n_epochs": [5, 10],
    "lr_all": [0.002, 0.005],
    "reg_all": [0.4, 0.6]
}

# Get the best params using GridSearchCV
gs = GridSearchCV(SVD, param_grid, measures=["rmse"], cv=3)
gs.fit(data_train)
best_params = gs.best_params["rmse"]
print(gs.best_score["rmse"])
print(gs.best_params["rmse"])

# Extract and train model with best params
svd_algo = SVD(n_epochs=best_params['n_epochs'],
               lr_all=best_params['lr_all'],
               reg_all=best_params['reg_all'])
svd_algo.fit(trainingSet)

from tqdm import tqdm
predictions = []
actuals = []
rmse_val = []
for col, row in tqdm(test.iterrows()):
    predictions.append(svd_algo.predict(row.userid, row.movieid).est)
    actuals.append(row.rating)

rmse_val = rmse(np.array(predictions), np.array(actuals))

print("Test Accuracy SVD = " + str(rmse_val))

import pickle
filename = 'SVD_14k'
outfile = open(filename,'wb')
pickle.dump(svd_algo,outfile)
outfile.close()

